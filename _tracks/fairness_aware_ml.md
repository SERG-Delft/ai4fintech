---
layout: default
track-id: 10
title: 10 - Fairness-Aware Machine Learning
leader: Cynthia Liem
---

# Track 10: Fairness-Aware Machine Learning

More and more software services in the banking domain rely on machine learning.
This makes it crucial that such services can be considered fair, and not influenced negatively by potential biases in the training data. Here, the banking domain introduces an additional, critical need for fairness, as the bank's algorithms affect customer's abilities to open a bank account, obtain a loan or mortgage, or buy a house.

This calls for machine learning and recommender system approaches that offer ways to quantify and mitigate algorithmic bias.
An open question at the moment is how fairness constraints can be expressed, and to what extent current approaches like stating desired statistical distributions of key attributes are sufficient.
Another question is how, given potentially biased ML results, subsequent ranking algorithms can be made aware of this bias so that it can adjust its ranks accordingly.
Lastly, fairness-aware machine learning calls for a clear ethical framework, which offers a well-defined for humans who are in control.

Related work:

- Sarah Bird, Ben Hutchinson, Krishnaram Kenthapadi, Emre Kiciman, Margaret Mitchell: Fairness-Aware Machine Learning: Practical Challenges and Lessons Learned. KDD 2019:3205-3206

- Sandy Manolios, Alan Hanjalic, Cynthia C. S. Liem: The influence of personal values on music taste: towards value-based music recommendations. RecSys 2019:501-505

- Nava Tintarev, Judith Masthoff: Explaining Recommendations: Design and Evaluation. Recommender Systems Handbook 2015:353-382

**Track leader:** Cynthia Liem
